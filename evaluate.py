import json
import argparse
import os

parser = argparse.ArgumentParser()
parser.add_argument("--candidate")
parser.add_argument("--production")
args = parser.parse_args()

candidate_path = args.candidate
production_path = args.production

# Helper pour crÃ©er un fichier metrics.json minimal
def create_default_metrics(path):
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "w") as f:
        json.dump({"f1": 0.0}, f, indent=2)
    print(f"Created default metrics file at {path}")


# ðŸ”¹ 1) VÃ©rifier fichier candidat
if not os.path.exists(candidate_path):
    print("âš  Aucun modÃ¨le candidat trouvÃ© â€” crÃ©ation automatique.")
    create_default_metrics(candidate_path)

# Charger les mÃ©triques candidat
with open(candidate_path) as f:
    cand = json.load(f)

cand_score = cand.get("f1", 0.0)


# ðŸ”¹ 2) VÃ©rifier fichier production
if not os.path.exists(production_path):
    print("âš  Aucun modÃ¨le production trouvÃ© â€” crÃ©ation automatique.")
    create_default_metrics(production_path)

# Charger mÃ©triques production
with open(production_path) as f:
    prod = json.load(f)

prod_score = prod.get("f1", 0.0)


# ðŸ”¹ 3) Comparaison
print(f"Candidat: {cand_score}, Production: {prod_score}")
is_better = cand_score > prod_score
print("Promote:", is_better)


# ðŸ”¹ 4) Output pour GitHub Actions
with open(os.environ['GITHUB_OUTPUT'], 'a') as fh:
    fh.write(f"promote={str(is_better).lower()}\n")
